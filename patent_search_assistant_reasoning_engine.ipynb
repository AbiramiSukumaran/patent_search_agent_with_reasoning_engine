{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YcBnq20nC6r"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ps8P8zxbdpHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU0F5ObiGgF4"
      },
      "source": [
        "# Patent Search with RAG-based Reasoning Engine, AlloyDB and LangChain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZft-jYpHmYv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "[LangChain on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview)\n",
        "is a managed service that helps you to build and deploy LangChain apps to a managed Reasoning Engine runtime.\n",
        "\n",
        "RAG (Retrieval-Augmented Generation) is an AI framework that combines the strengths of traditional information retrieval systems (such as databases) with the capabilities of generative large language models (LLMs).  By combining this extra knowledge with its own language skills, the AI can write text that is more accurate, up-to-date, and relevant to your specific needs.\n",
        "\n",
        "## Objectives\n",
        "\n",
        "In this tutorial, you will learn how to build and deploy an agent (model, tools, and reasoning) using the Vertex AI SDK for Python and AlloyDB for PostgreSQL LangChain integration.\n",
        "\n",
        "Your [LangChain](https://python.langchain.com/docs/get_started/introduction) agent will use an [AlloyDB Vector Store](https://github.com/googleapis/langchain-google-alloydb-pg-python/tree/main) to perform a similary search and retrieve related data to ground the LLM response.\n",
        "\n",
        "* Install and set up the AlloyDB for PostgreSQL for LangChain and the Vertex AI Python SDKs\n",
        "* Create an AlloyDB cluster and instance\n",
        "* Create an AlloyDB database user\n",
        "* Define a retriever to perform similarity searches\n",
        "* Use the LangChain agent template provided in the Vertex AI SDK for Reasoning Engine\n",
        "* Deploy and test your agent on Reasoning Engine in Vertex AI\n",
        "\n",
        "\n",
        "## Use Case\n",
        "Patent Search based on contextual relevance\n",
        "\n",
        "## Assumption\n",
        "1. **You must have completed the steps 2, 3, 4 and 5 in this codelab: first**\n",
        "https://codelabs.developers.google.com/patent-search-alloydb-geminilab\n",
        "\n",
        "2. You have this notebook implemented in the same account as your Google Cloud project account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RYpMytsZ882"
      },
      "source": [
        "### Install and import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_94DKOCX5pG"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet \"google-cloud-aiplatform[reasoningengine,langchain]\" langchain-google-alloydb-pg langchain-google-vertexai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "iaH5Wws6v4Tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-cloud-aiplatform[reasoningengine,langchain]==1.57.0 langchain-google-alloydb-pg==0.4.1 langchain-google-vertexai==1.0.4"
      ],
      "metadata": {
        "id": "Vw2m_zP9jlQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2520bbf159a9"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_google_alloydb_pg import AlloyDBEngine, AlloyDBVectorStore\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "import vertexai\n",
        "from vertexai.preview import reasoning_engines\n",
        "\n",
        "from vertexai.preview.reasoning_engines import ReasoningEngine, LangchainAgent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPKXjZrFZuUZ"
      },
      "source": [
        "### Authenticate to Google Cloud\n",
        "\n",
        "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGBuLA7aQ6O"
      },
      "source": [
        "### Define project information\n",
        "\n",
        "Initialize `gcloud` with your Project ID and resource location. At this time, only `us-central1` is supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vIeI4T_XVcDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee502f3e-f428-4279-d6af-df57b77a2284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "PROJECT_ID = \"YOUR_PROJECT\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esrdZL3IL6LN"
      },
      "source": [
        "## Create a Cloud Storage bucket\n",
        "\n",
        "Create or reuse and existing Cloud Storage bucket. Reasoning engine stages the artifacts of your applications in a Cloud Storage bucket as part of the deployment process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sptkevO4aUT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8a20c4-ac4e-49ee-f046-fad224ef7368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://img_gemini_test/...\n",
            "ServiceException: 409 A Cloud Storage bucket named 'img_gemini_test' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"
          ]
        }
      ],
      "source": [
        "STAGING_BUCKET_NAME = \"img_gemini_test\"  # @param {type:\"string\"}\n",
        "STAGING_BUCKET = f\"gs://{STAGING_BUCKET_NAME}\"\n",
        "\n",
        "# Create a Cloud Storage bucket, if it doesn't already exist\n",
        "!gsutil mb -c standard {STAGING_BUCKET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veGoLZBYZjxY"
      },
      "source": [
        "### Enable APIs\n",
        "\n",
        "This tutorial uses the following billable components of Google Cloud, which you'll need to enable for this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PcKjP3PiXDIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104d6c85-6422-486e-d7c8-e4043f7ba842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation \"operations/acat.p2-273845608377-0368c134-a3de-4de3-a66c-475940e89f07\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "!gcloud services enable aiplatform.googleapis.com alloydb.googleapis.com servicenetworking.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_yG0kddIvr7"
      },
      "source": [
        "## Set up AlloyDB\n",
        "\n",
        "Use the provided variable names or update the values to use a pre-exisiting AlloyDB cluster and instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XtiB5-LVVkv0"
      },
      "outputs": [],
      "source": [
        "REGION = \"us-central1\"  # @param {type:\"string\"}\n",
        "CLUSTER = \"vector-cluster\"  # @param {type:\"string\"}\n",
        "INSTANCE = \"vector-instance\"  # @param {type:\"string\"}\n",
        "DATABASE = \"postgres\"  # @param {type:\"string\"}\n",
        "TABLE_NAME = \"patents_data\"  # @param {type:\"string\"}\n",
        "PASSWORD = \"YOUR_DB_PASSWORD\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwwSQ2ZUf51F"
      },
      "source": [
        "### Create an AlloyDB cluster and primary instance\n",
        "\n",
        "This tutorial **assumes** you already have an AlloyDB cluster, instance, database, table, data and embeddings created. It should also have public IP and IAM authentication enabled.\n",
        "\n",
        "If not, **follow the steps 2, 3, 4 and 5 in this codelab: first**\n",
        "https://codelabs.developers.google.com/patent-search-alloydb-gemini\n",
        "\n",
        "\n",
        "Make sure to have **PUBLIC IP and authentication provided**\n",
        "\n",
        "If you do not complete the codelab mentioned above, you wouldn't be able to implement the rest of the steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCra5kJVKyg5"
      },
      "source": [
        "## Define the retriever tool\n",
        "\n",
        "Tools are interfaces that an agent, chain, or LLM can use to enable the Gemini model to interact with external systems, databases, document stores, and other APIs so that the model can get the most up-to-date information or take action with those systems.\n",
        "\n",
        "In this example, you'll define a function that will retrieve similar documents from the vector store using semantic search.\n",
        "\n",
        "For improved security measures, the tool wil use IAM-based authentication to authenticate to the databases instead of using the built-in user/password authentication."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_search(query: str) -> List[Document]:\n",
        "    \"\"\"Searches and returns patents.\n",
        "\n",
        "    Args:\n",
        "      query: The user query to search for related items\n",
        "\n",
        "    Returns:\n",
        "      List[Document]: A list of Documents\n",
        "    \"\"\"\n",
        "    engine = AlloyDBEngine.from_instance(\n",
        "        PROJECT_ID,\n",
        "        REGION,\n",
        "        CLUSTER,\n",
        "        INSTANCE,\n",
        "        DATABASE,\n",
        "        # Uncomment to use built-in authentication instead of IAM authentication\n",
        "        user=\"postgres\",\n",
        "        password=PASSWORD,\n",
        "    )\n",
        "    vector_store = AlloyDBVectorStore.create_sync(\n",
        "        engine,\n",
        "        table_name=TABLE_NAME,\n",
        "        embedding_service=VertexAIEmbeddings(\n",
        "            model_name=\"textembedding-gecko@latest\", project=PROJECT_ID\n",
        "        ),id_column=\"id\",content_column=\"abstract\",embedding_column=\"abstract_embeddings\",\n",
        "    )\n",
        "    retriever = vector_store.as_retriever()\n",
        "    return retriever.invoke(query)"
      ],
      "metadata": {
        "id": "1O5YZPPbgdOD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.similarity_search(\"patent related to natural language processing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW5TTBetXJfd",
        "outputId": "0b882e83-be58-46e8-f6f8-034e7a4e9bd8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Systems and methods for identifying word collocations in natural language texts. An example method comprises: performing, by a computing device, semantico-syntactic analysis of a natural language text to produce a plurality of semantic structures; generating, in view of relationships defined by the semantic structures, a raw list of word combinations; producing a list of collocations by applying a heuristic filter to the raw list of word combinations; and using the list of collocations to perform a natural language processing operation.'),\n",
              " Document(page_content='Aspects of the present invention provide a more universal, easy, natural, and vendor-agnostic interface to configure, manage, and/or monitor devices in networks. In embodiments, a user-friendly natural language interface voice interface may be used to â€œlive chatâ€\\x9d with one or more devices. In embodiments, a natural language input from a user intended for a target device is received and converted into one or more properly formed commands that are target-specific for the target device and may be executed by the target device. In embodiments, results from the execution of the one or more commands may be appropriately formatted for presentation to the user.'),\n",
              " Document(page_content='Methods and systems are provided for contextual language understanding. A natural language expression may be received at a single-turn model and a multi-turn model for determining an intent of a user. For example, the single-turn model may determine a first prediction of at least one of a domain classification, intent classification, and slot type of the natural language expression. The multi-turn model may determine a second prediction of at least one of a domain classification, intent classification, and slot type of the natural language expression. The first prediction and the second prediction may be combined to produce a final prediction relative to the intent of the natural language expression. An action may be performed based on the final prediction of the natural language expression.'),\n",
              " Document(page_content='Disclosed herein is a method for analyzing an utterance meaning. The method includes collecting a voice signal of an utterer; converting the collected voice signal into information in a text form, extracting a keyword of the text information from the text information, and deriving at least one utterance topic on the basis of the extracted keywords of the text information.')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERxxgFTcI3DC"
      },
      "source": [
        "## Deploy the service\n",
        "\n",
        "Now that you've specified a model, tools, and reasoning for your agent and tested it out, you're ready to deploy your agent as a remote service in Vertex AI!\n",
        "\n",
        "Here, you'll use the LangChain agent template provided in the Vertex AI SDK for Reasoning Engine, which brings together the model, tools, and reasoning that you've built up so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "k2nGSr2_JWcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf8b5de-8b9f-4278-c993-9ddb5672591f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.reasoning_engines._reasoning_engines:Using bucket img_gemini_test\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://img_gemini_test/reasoning_engine/reasoning_engine.pkl\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://img_gemini_test/reasoning_engine/requirements.txt\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating in-memory tarfile of extra_packages\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://img_gemini_test/reasoning_engine/dependencies.tar.gz\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating ReasoningEngine\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Create ReasoningEngine backing LRO: projects/273845608377/locations/us-central1/reasoningEngines/6234406851350364160/operations/5119270235630731264\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:ReasoningEngine created. Resource name: projects/273845608377/locations/us-central1/reasoningEngines/6234406851350364160\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:To use this ReasoningEngine in another session:\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/273845608377/locations/us-central1/reasoningEngines/6234406851350364160')\n"
          ]
        }
      ],
      "source": [
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\", staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "remote_app = reasoning_engines.ReasoningEngine.create(\n",
        "    reasoning_engines.LangchainAgent(\n",
        "        model=\"gemini-pro\",\n",
        "        tools=[similarity_search],\n",
        "        model_kwargs={\n",
        "            \"temperature\": 0.1,\n",
        "        },\n",
        "    ),\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform[reasoningengine,langchain]==1.57.0\",\n",
        "        \"langchain-google-alloydb-pg==0.4.1\",\n",
        "        \"langchain-google-vertexai==1.0.4\",\n",
        "    ],\n",
        "    display_name=\"PrebuiltAgent\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYqMpB16I4iH"
      },
      "source": [
        "## Try it out\n",
        "\n",
        "Query the remote app directly or retrieve the application endpoint via the resource ID or display name. The endpoint can be used from any Python environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "45hiyNyfJ9Zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602ff998-8311-47d7-d5cf-e6e2248f38c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Patents about natural language processing\n",
            "\n",
            "Here are some patents related to natural language processing (NLP):\n",
            "\n",
            "* **Systems and methods for identifying word collocations in natural language texts.** This patent describes a system and method for identifying word collocations in natural language texts. The system uses a semantic-syntactic analysis to identify relationships between words and then uses a heuristic filter to identify collocations.\n",
            "* **Aspects of the present invention provide a more universal, easy, natural, and vendor-agnostic interface to configure, manage, and/or monitor devices in networks.** This patent describes a system and method for providing a natural language interface for configuring, managing, and monitoring devices in networks. The system uses a voice interface to allow users to interact with the devices in a natural way.\n",
            "* **Methods and systems are provided for contextual language understanding.** This patent describes a system and method for understanding the context of natural language expressions. The system uses a single-turn model and a multi-turn model to determine the intent of a user. The system then combines the predictions from the two models to produce a final prediction.\n",
            "* **A computer-based system and method for responding to customer calls.** This patent describes a system and method for responding to customer calls. The system automatically determines whether a call meets existing customer criteria and then routes the call to an appropriate destination. The system can also use a voice prompt or a gaming system to interact with the customer.\n",
            "\n",
            "These are just a few examples of the many patents that have been issued in the field of NLP. NLP is a rapidly growing field, and new patents are being issued all the time.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = remote_app.query(input=\"Patents about natural language processing\")\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rLO17Uv9Xha-"
      },
      "outputs": [],
      "source": [
        "# Retrieve the application endpoint via the display name\n",
        "app_list = reasoning_engines.ReasoningEngine.list(filter='display_name=\"PrebuiltAgent\"')\n",
        "RESOURCE_ID = app_list[0].name\n",
        "\n",
        "# Retrieve the application endpoint via the resource ID\n",
        "remote_app = reasoning_engines.ReasoningEngine(\n",
        "    f\"projects/{PROJECT_ID}/locations/{LOCATION}/reasoningEngines/{RESOURCE_ID}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrZ9IjnAI5v9"
      },
      "source": [
        "## Clean up\n",
        "\n",
        "If you created a new project for this tutorial, delete the project. If you used an existing project and wish to keep it without the changes added in this tutorial, delete resources created for the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBc48ZHOJS6J"
      },
      "source": [
        "### Deleting the project\n",
        "\n",
        "The easiest way to eliminate billing is to delete the project that you created for the tutorial.\n",
        "\n",
        "1. In the Google Cloud console, go to the [Manage resources](https://console.cloud.google.com/iam-admin/projects?_ga=2.235586881.1783688455.1719351858-1945987529.1719351858) page.\n",
        "1. In the project list, select the project that you want to delete, and then click Delete.\n",
        "1. In the dialog, type the project ID, and then click Shut down to delete the project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed-BFtW-JPbI"
      },
      "source": [
        "### Deleting tutorial resources\n",
        "\n",
        "Delete the reasoning engine instance(s) and AlloyDB cluster and instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgNlHrxkb6c-"
      },
      "outputs": [],
      "source": [
        "# Delete the ReasoningEngine instance\n",
        "remote_app.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goyrqS2_I8Hs"
      },
      "outputs": [],
      "source": [
        "# Or delete all Reasoning Engine apps\n",
        "apps = reasoning_engines.ReasoningEngine.list()\n",
        "for app in apps:\n",
        "    app.delete()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odvj8aKpb3Wi"
      },
      "outputs": [],
      "source": [
        "# Delete the AlloyDB cluster and instance\n",
        "!gcloud alloydb clusters delete {CLUSTER} \\\n",
        "  --region={REGION} \\\n",
        "  --project={PROJECT_ID} \\\n",
        "  --force \\\n",
        "  --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NbUPwEfI62R"
      },
      "source": [
        "## What's next\n",
        "\n",
        "* Dive deeper into [LangChain on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/reasoning-engine/overview).\n",
        "* Learn more about the [AlloyDB for LangChain library](https://github.com/googleapis/langchain-google-alloydb-pg-python).\n",
        "* Explore other [Reasoning Engine samples](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/reasoning-engine)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}